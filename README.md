# Portfolio of course work for my Sensor Fusion NanoDegree (Udacity)
[![alt text](https://github.com/thienan092/Sensor-Fusion-ND/blob/main/media/big-decor-image.jpg)](https://www.udacity.com/course/sensor-fusion-engineer-nanodegree--nd313)

Program Overview:

Learn to fuse lidar point clouds, radar signatures, and camera images using Kalman Filters to perceive the environment and detect and track vehicles and pedestrians over time. 

## Projects

[<h2>Lidar Obstacle Detection</h2>](https://github.com/thienan092/Sensor-Fusion-ND/tree/main/Lidar%20Obstacle%20Detection)

<h4>Description: </h4>
<p>
Detect other cars on the road using raw lidar data from Udacityâ€™s real self-driving car, Carla! Implement custom ransac and euclidean clustering algorithms.

* Data set: Pull the data [here](https://github.com/udacity/SFND_Lidar_Obstacle_Detection/tree/master/src/sensors/data) and drop it into 'src\sensors\data' directory. 
</p>


[<h2>Camera and Lidar Fusion</h2>](https://github.com/thienan092/Sensor-Fusion-ND/tree/main/Camera%20and%20Lidar%20Fusion)

<h4>Description: </h4>
<p>
Detect and track objects from the benchmark KITTI dataset. Classify those objects and project them into three dimensions. Fuse those projections together with lidar data to create 3D objects to track over time. 

* Data set: Pull the model weights [here](https://github.com/udacity/SFND_3D_Object_Tracking/tree/master/dat) and the data [here](https://github.com/udacity/SFND_3D_Object_Tracking/tree/master/images) then drop them into 'dat' and 'images' directories. 
</p>
